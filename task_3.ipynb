{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "361c7d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CADEC span evaluation â€” notebook-only utilities (no argparse, no __main__)\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Set, Dict\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Span:\n",
    "    label: str\n",
    "    start: int\n",
    "    end: int\n",
    "\n",
    "RANGE_RE = re.compile(r\"(\\d+)\\s+(\\d+)\")\n",
    "\n",
    "def parse_ann(path: Path) -> List[Span]:\n",
    "    spans: List[Span] = []\n",
    "    for line in path.read_text(encoding=\"utf-8\").splitlines():\n",
    "        line = line.strip()\n",
    "        if not line or line[0] in {\"#\", \"A\", \"R\"} or not line.startswith(\"T\"):\n",
    "            continue\n",
    "        parts = line.split(\"\\t\")\n",
    "        if len(parts) < 2:\n",
    "            continue\n",
    "        head = parts[1]  # e.g. \"ADR 9 19\" or \"ADR 9 19;29 50\"\n",
    "        label = head.split()[0]\n",
    "        for m in RANGE_RE.finditer(head[len(label):]):\n",
    "            s, e = int(m.group(1)), int(m.group(2))\n",
    "            if e > s:\n",
    "                spans.append(Span(label, s, e))\n",
    "    # unique & sorted\n",
    "    spans = sorted(set(spans), key=lambda x: (x.label, x.start, x.end))\n",
    "    return spans\n",
    "\n",
    "def to_set(spans: List[Span]) -> Set[Tuple[str,int,int]]:\n",
    "    return {(s.label, s.start, s.end) for s in spans}\n",
    "\n",
    "def prf1(tp: int, fp: int, fn: int) -> Tuple[float,float,float]:\n",
    "    p = tp/(tp+fp) if tp+fp else 0.0\n",
    "    r = tp/(tp+fn) if tp+fn else 0.0\n",
    "    f = 2*p*r/(p+r) if p+r else 0.0\n",
    "    return p, r, f\n",
    "\n",
    "def evaluate_one(original_dir: Path, predicted_dir: Path, text_dir: Path, file_basename: str) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    file_basename: e.g. 'ARTHROTEC.17' (no extension). We will read:\n",
    "      - {original_dir}/{file_basename}.ann  (gold)\n",
    "      - {predicted_dir}/{file_basename}.ann (pred)\n",
    "      - {text_dir}/{file_basename}.txt      (raw text)\n",
    "    \"\"\"\n",
    "    base = file_basename[:-4] if file_basename.lower().endswith(\".ann\") else file_basename\n",
    "    gold_ann = Path(original_dir) / f\"{base}.ann\"\n",
    "    pred_ann = Path(predicted_dir) / f\"{base}.ann\"\n",
    "    txt_path = Path(text_dir) / f\"{base}.txt\"\n",
    "\n",
    "    if not gold_ann.exists():\n",
    "        raise FileNotFoundError(f\"Gold not found: {gold_ann}\")\n",
    "    if not pred_ann.exists():\n",
    "        raise FileNotFoundError(f\"Predicted not found: {pred_ann}\")\n",
    "    if not txt_path.exists():\n",
    "        raise FileNotFoundError(f\"Text not found: {txt_path}\")\n",
    "\n",
    "    raw = txt_path.read_text(encoding=\"utf-8\")\n",
    "    gold = parse_ann(gold_ann)\n",
    "    pred = parse_ann(pred_ann)\n",
    "\n",
    "    def with_text(spans: List[Span]):\n",
    "        out = []\n",
    "        for s in spans:\n",
    "            seg = raw[s.start:s.end].replace(\"\\n\", \" \")\n",
    "            out.append((s.label, s.start, s.end, seg))\n",
    "        return out\n",
    "\n",
    "    gold_t = with_text(gold)\n",
    "    pred_t = with_text(pred)\n",
    "\n",
    "    print(\"\\n--- Ground Truth Entities ---\")\n",
    "    for t in gold_t:\n",
    "        print(t)\n",
    "\n",
    "    print(\"\\n--- Predicted Entities ---\")\n",
    "    for t in pred_t:\n",
    "        print(t)\n",
    "\n",
    "    gset, pset = to_set(gold), to_set(pred)\n",
    "    tp = len(gset & pset)\n",
    "    fp = len(pset - gset)\n",
    "    fn = len(gset - pset)\n",
    "    P, R, F = prf1(tp, fp, fn)\n",
    "\n",
    "    print(\"\\n--- Evaluation Metrics ---\")\n",
    "    print(f\"Precision: {P:.2f}\")\n",
    "    print(f\"Recall:    {R:.2f}\")\n",
    "    print(f\"F1-score:  {F:.2f}\")\n",
    "\n",
    "    return {\"precision\": P, \"recall\": R, \"f1\": F, \"tp\": tp, \"fp\": fp, \"fn\": fn}\n",
    "\n",
    "def list_basenames(folder: Path) -> List[str]:\n",
    "    \"\"\"Return basenames (without extension) for .ann files in a folder.\"\"\"\n",
    "    return sorted(p.stem for p in folder.glob(\"*.ann\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f4e8649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold files (first 20):\n",
      "['ARTHROTEC.1', 'ARTHROTEC.10', 'ARTHROTEC.100', 'ARTHROTEC.101', 'ARTHROTEC.102', 'ARTHROTEC.103', 'ARTHROTEC.104', 'ARTHROTEC.105', 'ARTHROTEC.106', 'ARTHROTEC.107', 'ARTHROTEC.108', 'ARTHROTEC.109', 'ARTHROTEC.11', 'ARTHROTEC.110', 'ARTHROTEC.111', 'ARTHROTEC.112', 'ARTHROTEC.113', 'ARTHROTEC.114', 'ARTHROTEC.115', 'ARTHROTEC.116'] ... total=1250\n",
      "\n",
      "Predicted files (first 20):\n",
      "['ARTHROTEC.1', 'ARTHROTEC.10', 'ARTHROTEC.100', 'ARTHROTEC.11', 'ARTHROTEC.12', 'ARTHROTEC.13', 'ARTHROTEC.14', 'ARTHROTEC.15', 'ARTHROTEC.16', 'ARTHROTEC.17', 'ARTHROTEC.18', 'ARTHROTEC.19', 'ARTHROTEC.2', 'ARTHROTEC.20', 'ARTHROTEC.21', 'ARTHROTEC.22', 'ARTHROTEC.23', 'ARTHROTEC.24', 'ARTHROTEC.25', 'ARTHROTEC.26'] ... total=103\n",
      "\n",
      "--- Ground Truth Entities ---\n",
      "('ADR', 74, 88, 'abdominal pain')\n",
      "('ADR', 100, 117, 'mentstrual cramps')\n",
      "('ADR', 118, 135, 'diarreah cramping')\n",
      "('ADR', 221, 241, 'lower abdominal pain')\n",
      "('ADR', 400, 408, 'GI bleed')\n",
      "('ADR', 477, 501, 'heavy menstrual bleeding')\n",
      "('ADR', 576, 582, 'anemia')\n",
      "('ADR', 594, 607, 'gastric bleed')\n",
      "('ADR', 674, 679, 'dizzy')\n",
      "('ADR', 684, 696, 'light headed')\n",
      "('ADR', 711, 747, 'acidic bile at the back of my throat')\n",
      "('Drug', 312, 317, 'Advil')\n",
      "('Symptom', 331, 349, 'inflammation in my')\n",
      "('Symptom', 350, 354, 'neck')\n",
      "('Symptom', 359, 371, 'back muscles')\n",
      "\n",
      "--- Predicted Entities ---\n",
      "('ADR', 74, 88, 'abdominal pain')\n",
      "('ADR', 221, 241, 'lower abdominal pain')\n",
      "('ADR', 674, 679, 'dizzy')\n",
      "('Disease', 243, 252, 'i was put')\n",
      "('Disease', 249, 260, 'put on this')\n",
      "('Disease', 400, 408, 'GI bleed')\n",
      "('Disease', 576, 582, 'anemia')\n",
      "('Disease', 594, 607, 'gastric bleed')\n",
      "('Drug', 312, 317, 'Advil')\n",
      "('Symptom', 684, 696, 'light headed')\n",
      "('Symptom', 711, 722, 'acidic bile')\n",
      "\n",
      "--- Evaluation Metrics ---\n",
      "Precision: 0.36\n",
      "Recall:    0.27\n",
      "F1-score:  0.31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.36363636363636365,\n",
       " 'recall': 0.26666666666666666,\n",
       " 'f1': 0.30769230769230765,\n",
       " 'tp': 4,\n",
       " 'fp': 7,\n",
       " 'fn': 11}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# ---- EDIT THESE THREE PATHS TO MATCH YOUR MACHINE ----\n",
    "original_dir = Path(\"/Users/anjalikulkarni/Desktop/Assignment1/CADEC-lPWNPfjE-/data/cadec/original\")  # gold annotations\n",
    "predicted_dir = Path(\"/Users/anjalikulkarni/Desktop/Assignment1/predicted\")                             # your model outputs\n",
    "text_dir      = Path(\"/Users/anjalikulkarni/Desktop/Assignment1/CADEC-lPWNPfjE-/data/cadec/text\")       # raw texts\n",
    "\n",
    "# 1) Show what's available so you can pick the correct basename\n",
    "print(\"Gold files (first 20):\")\n",
    "golds = list_basenames(original_dir)\n",
    "print(golds[:20], f\"... total={len(golds)}\")\n",
    "\n",
    "print(\"\\nPredicted files (first 20):\")\n",
    "preds = list_basenames(predicted_dir)\n",
    "print(preds[:20], f\"... total={len(preds)}\")\n",
    "\n",
    "# 2) Pick the file you want to score (must exist in BOTH gold and predicted)\n",
    "# Example: \"ARTHROTEC.17\" OR \"VOLTAREN.9\" etc. No extension.\n",
    "file_basename = \"ARTHROTEC.17\"   # <-- change this to one that appears in BOTH lists\n",
    "\n",
    "if file_basename not in golds:\n",
    "    raise FileNotFoundError(f\"'{file_basename}.ann' not in gold dir {original_dir}\")\n",
    "if file_basename not in preds:\n",
    "    raise FileNotFoundError(f\"'{file_basename}.ann' not in predicted dir {predicted_dir}\")\n",
    "\n",
    "# 3) Run evaluation\n",
    "metrics = evaluate_one(original_dir, predicted_dir, text_dir, file_basename)\n",
    "metrics\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
