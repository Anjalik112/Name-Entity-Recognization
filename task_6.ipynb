{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad3cac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 6 — ADR code assignment (string-match vs embedding-match)\n",
    "# Jupyter-friendly library cell (no argparse; import-free outside standard libs)\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import math, os, re\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# -------- Data classes --------\n",
    "@dataclass(frozen=True)\n",
    "class Range:\n",
    "    start: int\n",
    "    end: int\n",
    "\n",
    "@dataclass\n",
    "class AnnSpan:\n",
    "    label: str              # ADR, Drug, Disease, Symptom (from original or predicted)\n",
    "    ranges: List[Range]\n",
    "    text: str               # pulled from raw text\n",
    "\n",
    "@dataclass\n",
    "class SctSpan:\n",
    "    code: str               # SNOMED CT code (or MedDRA if your sct dir has those)\n",
    "    ranges: List[Range]\n",
    "    text: str               # mapped term from sct file (we treat this as \"standard_text\")\n",
    "\n",
    "@dataclass\n",
    "class Joined:\n",
    "    code: str\n",
    "    standard_text: str      # sct span text (mapped term)\n",
    "    label_type: str         # from original ann (ADR/Drug/Disease/Symptom)\n",
    "    gt_text: str            # from original ann\n",
    "    gt_ranges: List[Range]\n",
    "\n",
    "# -------- Parsers --------\n",
    "RANGE_RE = re.compile(r\"(\\d+)\\s+(\\d+)\")\n",
    "\n",
    "def _read_text(p: Path) -> str:\n",
    "    return p.read_text(encoding=\"utf-8\")\n",
    "\n",
    "def _surface(text: str, ranges: List[Range]) -> str:\n",
    "    # joins discontiguous spans with a space — same behavior as your other tasks\n",
    "    return \" \".join(text[r.start:r.end].replace(\"\\n\", \" \") for r in ranges)\n",
    "\n",
    "def _parse_ann_spans(path: Path, raw: str, accept_labels: Optional[set[str]] = None) -> List[AnnSpan]:\n",
    "    \"\"\"\n",
    "    Parse brat T-lines:  T1\\tADR 10 20;30 40\\ttext...\n",
    "    Keeps multi-range spans; pulls surface from raw text.\n",
    "    \"\"\"\n",
    "    spans: List[AnnSpan] = []\n",
    "    if not path.exists():\n",
    "        return spans\n",
    "    for line in path.read_text(encoding=\"utf-8\").splitlines():\n",
    "        line = line.strip()\n",
    "        if not line or not line.startswith(\"T\") or line.startswith(\"TT\"):\n",
    "            continue\n",
    "        parts = line.split(\"\\t\")\n",
    "        if len(parts) < 2:\n",
    "            continue\n",
    "        head = parts[1]                      # \"LABEL s e; s e ...\"\n",
    "        label = head.split()[0]\n",
    "        if accept_labels and label not in accept_labels:\n",
    "            continue\n",
    "        rr: List[Range] = []\n",
    "        for m in RANGE_RE.finditer(head[len(label):]):\n",
    "            s, e = int(m.group(1)), int(m.group(2))\n",
    "            if e > s:\n",
    "                rr.append(Range(s, e))\n",
    "        if not rr:\n",
    "            continue\n",
    "        txt = _surface(raw, rr)\n",
    "        spans.append(AnnSpan(label=label, ranges=rr, text=txt))\n",
    "    return spans\n",
    "\n",
    "def _parse_sct_spans(path: Path, raw: str) -> List[SctSpan]:\n",
    "    \"\"\"\n",
    "    Parse mapped-code TT-lines:  TT1\\t<CODE> <start> <end>[; ...]\\t<mapped term>\n",
    "    If mapped term missing, uses surface from raw.\n",
    "    \"\"\"\n",
    "    out: List[SctSpan] = []\n",
    "    if not path.exists():\n",
    "        return out\n",
    "    for line in path.read_text(encoding=\"utf-8\").splitlines():\n",
    "        line = line.strip()\n",
    "        if not line or not line.startswith(\"TT\"):\n",
    "            continue\n",
    "        parts = line.split(\"\\t\")\n",
    "        if len(parts) < 2:\n",
    "            continue\n",
    "        head = parts[1].strip()              # \"<CODE> s e [; s e ...]\"\n",
    "        bits = head.split()\n",
    "        code = bits[0]\n",
    "        rr: List[Range] = []\n",
    "        for m in RANGE_RE.finditer(head[len(code):]):\n",
    "            s, e = int(m.group(1)), int(m.group(2))\n",
    "            if e > s:\n",
    "                rr.append(Range(s, e))\n",
    "        if not rr:\n",
    "            continue\n",
    "        mapped = parts[2].strip() if len(parts) >= 3 else \"\"\n",
    "        if not mapped:\n",
    "            mapped = _surface(raw, rr)\n",
    "        out.append(SctSpan(code=code, ranges=rr, text=mapped))\n",
    "    return out\n",
    "\n",
    "# -------- Overlap helpers --------\n",
    "def _spans_overlap_len(ar: List[Range], br: List[Range]) -> int:\n",
    "    tot = 0\n",
    "    for a in ar:\n",
    "        for b in br:\n",
    "            s = max(a.start, b.start)\n",
    "            e = min(a.end, b.end)\n",
    "            if e > s:\n",
    "                tot += (e - s)\n",
    "    return tot\n",
    "\n",
    "# -------- Join original ↔ sct by max overlap --------\n",
    "def build_joined(original_spans: List[AnnSpan], sct_spans: List[SctSpan]) -> List[Joined]:\n",
    "    out: List[Joined] = []\n",
    "    for g in original_spans:\n",
    "        best: Optional[SctSpan] = None\n",
    "        best_ol = 0\n",
    "        for t in sct_spans:\n",
    "            ol = _spans_overlap_len(g.ranges, t.ranges)\n",
    "            if ol > best_ol:\n",
    "                best_ol = ol\n",
    "                best = t\n",
    "        if best and best_ol > 0:\n",
    "            out.append(Joined(\n",
    "                code=best.code,\n",
    "                standard_text=best.text,\n",
    "                label_type=g.label,\n",
    "                gt_text=g.text,\n",
    "                gt_ranges=g.ranges\n",
    "            ))\n",
    "        else:\n",
    "            out.append(Joined(\n",
    "                code=\"\",\n",
    "                standard_text=\"\",\n",
    "                label_type=g.label,\n",
    "                gt_text=g.text,\n",
    "                gt_ranges=g.ranges\n",
    "            ))\n",
    "    return out\n",
    "\n",
    "# -------- Matching (fuzzy & embedding) --------\n",
    "def _norm(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", s).strip().casefold()\n",
    "\n",
    "def fuzzy_score(a: str, b: str) -> float:\n",
    "    \"\"\"Return 0..100. Uses rapidfuzz if available, else difflib (token-insensitive).\"\"\"\n",
    "    try:\n",
    "        from rapidfuzz import fuzz\n",
    "        return float(fuzz.token_set_ratio(a, b))\n",
    "    except Exception:\n",
    "        import difflib\n",
    "        return 100.0 * difflib.SequenceMatcher(None, _norm(a), _norm(b)).ratio()\n",
    "\n",
    "def embed_model_loader(model_name: str):\n",
    "    try:\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        return SentenceTransformer(model_name)\n",
    "    except Exception as ex:\n",
    "        raise RuntimeError(\n",
    "            f\"Embedding model '{model_name}' not available.\\n\"\n",
    "            f\"Try: pip install sentence-transformers\\nDetails: {ex}\"\n",
    "        )\n",
    "\n",
    "def embed_vectors(model, texts: List[str]):\n",
    "    # model.encode returns np.ndarray; normalize for cosine\n",
    "    return model.encode(texts, normalize_embeddings=True, convert_to_numpy=True)\n",
    "\n",
    "def cosine_sim_matrix(cat_vecs, q_vec):\n",
    "    # both L2-normalized; cosine == dot\n",
    "    import numpy as np\n",
    "    return cat_vecs @ q_vec\n",
    "\n",
    "# -------- Pretty print helpers --------\n",
    "def fmt_ranges(rr: List[Range]) -> str:\n",
    "    return \";\".join(f\"{r.start}-{r.end}\" for r in rr)\n",
    "\n",
    "def print_table(rows: List[List[str]]):\n",
    "    if not rows:\n",
    "        return\n",
    "    widths = [max(len(str(row[i])) for row in rows) for i in range(len(rows[0]))]\n",
    "    for i, row in enumerate(rows):\n",
    "        line = \" | \".join(str(row[j]).ljust(widths[j]) for j in range(len(row)))\n",
    "        print(line)\n",
    "        if i == 0:\n",
    "            print(\"-+-\".join(\"-\" * w for w in widths))\n",
    "\n",
    "# -------- Runner (call from next cell) --------\n",
    "def run_task6_for_file(\n",
    "    text_dir: str | Path,\n",
    "    original_dir: str | Path,\n",
    "    sct_dir: str | Path,\n",
    "    predicted_dir: str | Path,\n",
    "    file_basename: str,                           # e.g., \"ARTHROTEC.24\" (with or w/o .txt/.ann)\n",
    "    embed_model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    topn: int = 3,                                # kept for parity; we currently show top-1 per method\n",
    "    min_fuzzy: float = 60.0,\n",
    "    min_cos: float = 0.35,\n",
    "):\n",
    "    base = file_basename\n",
    "    base = base[:-4] if base.lower().endswith(\".txt\") or base.lower().endswith(\".ann\") else base\n",
    "\n",
    "    text_path = Path(text_dir) / f\"{base}.txt\"\n",
    "    orig_path = Path(original_dir) / f\"{base}.ann\"\n",
    "    sct_path  = Path(sct_dir) / f\"{base}.ann\"\n",
    "    pred_path = Path(predicted_dir) / f\"{base}.ann\"\n",
    "\n",
    "    if not text_path.exists():\n",
    "        raise FileNotFoundError(text_path)\n",
    "    raw = _read_text(text_path)\n",
    "\n",
    "    # 1) Parse\n",
    "    original_spans   = _parse_ann_spans(orig_path, raw, accept_labels=None)   # all labels\n",
    "    sct_spans        = _parse_sct_spans(sct_path, raw)\n",
    "    predicted_spans  = _parse_ann_spans(pred_path, raw, accept_labels={\"ADR\"})  # only ADR\n",
    "\n",
    "    # 2) Join original ↔ sct by overlap\n",
    "    joined = build_joined(original_spans, sct_spans)\n",
    "\n",
    "    # 3) ADR catalog from joined (code + standardized text)\n",
    "    catalog = [(j.code, j.standard_text, j.gt_text, j.label_type) for j in joined if j.label_type == \"ADR\" and j.code]\n",
    "    if not catalog:\n",
    "        print(\"No ADR-coded entries found in sct↔original join for this file.\")\n",
    "    else:\n",
    "        print(f\"[Info] ADR catalog size: {len(catalog)}\")\n",
    "\n",
    "    # 4) Prepare embedding model & vectors for catalog standard_text\n",
    "    emb_model = None\n",
    "    emb_cat = None\n",
    "    if catalog:\n",
    "        try:\n",
    "            emb_model = embed_model_loader(embed_model_name)\n",
    "            emb_cat = embed_vectors(emb_model, [c[1] for c in catalog])  # embeddings of standard_text\n",
    "        except Exception as ex:\n",
    "            print(f\"[WARN] Embedding model unavailable: {ex}\")\n",
    "            emb_model = None\n",
    "\n",
    "    # 5) Compare for each predicted ADR (top-1 fuzzy & top-1 embedding)\n",
    "    header = [\n",
    "        \"Pred ADR text\",\n",
    "        \"Fuzzy code\", \"Fuzzy std text\", \"Fuzzy score\",\n",
    "        \"Embed code\", \"Embed std text\", \"Cosine\"\n",
    "    ]\n",
    "    rows = [header]\n",
    "    agree = 0\n",
    "    total = 0\n",
    "\n",
    "    for p in predicted_spans:\n",
    "        total += 1\n",
    "        ptxt = p.text\n",
    "\n",
    "        # (a) fuzzy best\n",
    "        best_f = (-1.0, \"\", \"\")  # (score, code, std_text)\n",
    "        for code, std_text, gt_text, lab in catalog:\n",
    "            sc = fuzzy_score(ptxt, std_text)\n",
    "            if sc > best_f[0]:\n",
    "                best_f = (sc, code, std_text)\n",
    "        fuzzy_code, fuzzy_txt, fuzzy_sc = \"\", \"\", 0.0\n",
    "        if best_f[0] >= min_fuzzy:\n",
    "            fuzzy_sc, fuzzy_code, fuzzy_txt = best_f[0], best_f[1], best_f[2]\n",
    "\n",
    "        # (b) embedding best\n",
    "        embed_code, embed_txt, embed_cos = \"\", \"\", 0.0\n",
    "        if emb_model is not None and emb_cat is not None and len(catalog) > 0:\n",
    "            import numpy as np\n",
    "            v = embed_vectors(emb_model, [ptxt])[0]      # shape (d,)\n",
    "            sims = cosine_sim_matrix(emb_cat, v)         # shape (N,)\n",
    "            idx = int(sims.argmax())\n",
    "            cs = float(sims[idx])\n",
    "            if cs >= min_cos:\n",
    "                embed_code, embed_txt, embed_cos = catalog[idx][0], catalog[idx][1], cs\n",
    "\n",
    "        rows.append([\n",
    "            ptxt,\n",
    "            fuzzy_code, fuzzy_txt, f\"{fuzzy_sc:.1f}\",\n",
    "            embed_code, embed_txt, f\"{embed_cos:.3f}\"\n",
    "        ])\n",
    "\n",
    "        if fuzzy_code and embed_code and (fuzzy_code == embed_code):\n",
    "            agree += 1\n",
    "\n",
    "    print(\"\\n=== ADR Code Assignment (Predicted ADRs) ===\")\n",
    "    print_table(rows)\n",
    "\n",
    "    if total > 0:\n",
    "        print(f\"\\nAgreement (fuzzy vs embedding) on assigned code: {agree}/{total} = {agree/total:.2%}\")\n",
    "    else:\n",
    "        print(\"\\nNo predicted ADR spans found for this file.\")\n",
    "\n",
    "    # 6) Show joined catalog for transparency\n",
    "    print(\"\\n=== Joined catalog (original ↔ sct) for this file ===\")\n",
    "    cat_rows = [[\"Code\", \"Standard Text (from sct)\", \"Label\", \"GT Text\", \"GT Ranges\"]]\n",
    "    for j in joined:\n",
    "        if j.label_type != \"ADR\":\n",
    "            continue\n",
    "        if not j.code:\n",
    "            # skip ADRs with no mapped code\n",
    "            continue\n",
    "        cat_rows.append([j.code, j.standard_text, j.label_type, j.gt_text, fmt_ranges(j.gt_ranges)])\n",
    "    print_table(cat_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73249384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "### Processing: ARTHROTEC.6\n",
      "==========================================================================================\n",
      "[Info] ADR catalog size: 9\n",
      "\n",
      "=== ADR Code Assignment (Predicted ADRs) ===\n",
      "Pred ADR text    | Fuzzy code | Fuzzy std text            | Fuzzy score | Embed code | Embed std text   | Cosine\n",
      "-----------------+------------+---------------------------+-------------+------------+------------------+-------\n",
      "stomach pain     | 271681002  | stomach pain              | 100.0       | 271681002  | stomach pain     | 1.000 \n",
      "slight nausea    | 422587007  | slight nausea             | 100.0       | 422587007  | slight nausea    | 1.000 \n",
      "cramps           | 9991008    | abdominal cramps and pain | 100.0       | 9991008    | abdominal cramps | 0.826 \n",
      "abdominal cramps | 9991008    | abdominal cramps and pain | 100.0       | 9991008    | abdominal cramps | 1.000 \n",
      "pain relief      |            |                           | 0.0         | 271681002  | stomach pain     | 0.433 \n",
      "\n",
      "Agreement (fuzzy vs embedding) on assigned code: 4/5 = 80.00%\n",
      "\n",
      "=== Joined catalog (original ↔ sct) for this file ===\n",
      "Code      | Standard Text (from sct)  | Label | GT Text                   | GT Ranges      \n",
      "----------+---------------------------+-------+---------------------------+----------------\n",
      "271681002 | stomach pain              | ADR   | stomach pain              | 14-26          \n",
      "422587007 | slight nausea             | ADR   | slight nausea             | 32-45          \n",
      "47268002  | reflux                    | ADR   | reflux                    | 52-58          \n",
      "9991008   | abdominal cramps and pain | ADR   | abdominal cramps and pain | 152-161;166-181\n",
      "162076009 | abdominal gas             | ADR   | abdominal gas             | 152-161;162-165\n",
      "9991008   | abdominal cramps          | ADR   | abdominal cramps          | 228-244        \n",
      "9991008   | abdominal cramps          | ADR   | abdominal cramps          | 466-475;480-486\n",
      "43364001  | abdominal discomfort      | ADR   | abdominal discomfort      | 466-475;491-501\n",
      "162076009 | abdominal gas             | ADR   | abdominal gas             | 466-475;476-479\n",
      "\n",
      "==========================================================================================\n",
      "### Processing: ARTHROTEC.7\n",
      "==========================================================================================\n",
      "[Info] ADR catalog size: 6\n",
      "\n",
      "=== ADR Code Assignment (Predicted ADRs) ===\n",
      "Pred ADR text                | Fuzzy code | Fuzzy std text                                   | Fuzzy score | Embed code | Embed std text                                   | Cosine\n",
      "-----------------------------+------------+--------------------------------------------------+-------------+------------+--------------------------------------------------+-------\n",
      "severe sudden onset headache | 25064002   | severe sudden onset headache in the back of head | 100.0       | 25064002   | severe sudden onset headache in the back of head | 0.884 \n",
      "problems                     |            |                                                  | 0.0         |            |                                                  | 0.000 \n",
      "\n",
      "Agreement (fuzzy vs embedding) on assigned code: 1/2 = 50.00%\n",
      "\n",
      "=== Joined catalog (original ↔ sct) for this file ===\n",
      "Code     | Standard Text (from sct)                         | Label | GT Text                                          | GT Ranges\n",
      "---------+--------------------------------------------------+-------+--------------------------------------------------+----------\n",
      "25064002 | severe sudden onset headache in the back of head | ADR   | severe sudden onset headache in the back of head | 17-65    \n",
      "69791001 | BP was extrememly high                           | ADR   | BP was extrememly high                           | 91-113   \n",
      "86651002 | pulse was high                                   | ADR   | pulse was high                                   | 119-133  \n",
      "69791001 | high BP                                          | ADR   | high BP                                          | 226-233  \n",
      "86651002 | pulse is still extremely high                    | ADR   | pulse is still extremely high                    | 295-324  \n",
      "3424008  | tachycardia                                      | ADR   | tachycardia                                      | 548-559  \n",
      "\n",
      "==========================================================================================\n",
      "### Processing: LIPITOR.344\n",
      "==========================================================================================\n",
      "[Info] ADR catalog size: 13\n",
      "\n",
      "=== ADR Code Assignment (Predicted ADRs) ===\n",
      "Pred ADR text                      | Fuzzy code | Fuzzy std text | Fuzzy score | Embed code | Embed std text | Cosine\n",
      "-----------------------------------+------------+----------------+-------------+------------+----------------+-------\n",
      "headache                           | 25064002   | Mild headache  | 100.0       | 25064002   | Mild headache  | 0.775 \n",
      "muscle cramps in legs and left arm | 55300003   | muscle cramps  | 100.0       | 55300003   | muscle cramps  | 0.820 \n",
      "spasms                             | 55300003   | Muscle spasms  | 100.0       | 45352006   | spasms         | 1.000 \n",
      "\n",
      "Agreement (fuzzy vs embedding) on assigned code: 2/3 = 66.67%\n",
      "\n",
      "=== Joined catalog (original ↔ sct) for this file ===\n",
      "Code         | Standard Text (from sct)  | Label | GT Text                   | GT Ranges      \n",
      "-------------+---------------------------+-------+---------------------------+----------------\n",
      "57676002     | Very sore and achy joints | ADR   | Very sore and achy joints | 0-25           \n",
      "25064002     | Mild headache             | ADR   | Mild headache             | 56-69          \n",
      "419723007    | foggy                     | ADR   | foggy                     | 98-103         \n",
      "55300003     | muscle cramps             | ADR   | muscle cramps             | 132-145        \n",
      "55300003     | Muscle spasms             | ADR   | Muscle spasms             | 168-181        \n",
      "CONCEPT_LESS | leg buzzing sensation     | ADR   | leg buzzing sensation     | 212-215;240-257\n",
      "45352006     | spasms                    | ADR   | spasms                    | 275-281        \n",
      "60238002     | muscles quivering         | ADR   | muscles quivering         | 300-307;323-332\n",
      "162221009    | restless                  | ADR   | restless                  | 364-372        \n",
      "301345002    | hard to sleep             | ADR   | hard to sleep             | 386-399        \n",
      "55300003     | muscle cramps             | ADR   | muscle cramps             | 501-514        \n",
      "45352006     | spasms                    | ADR   | spasms                    | 515-521        \n",
      "57676002     | joint pain                | ADR   | joint pain                | 527-537        \n",
      "\n",
      "==========================================================================================\n",
      "### Processing: VOLTAREN.10\n",
      "==========================================================================================\n",
      "[Info] ADR catalog size: 1\n",
      "\n",
      "=== ADR Code Assignment (Predicted ADRs) ===\n",
      "Pred ADR text | Fuzzy code | Fuzzy std text | Fuzzy score | Embed code | Embed std text | Cosine\n",
      "--------------+------------+----------------+-------------+------------+----------------+-------\n",
      "\n",
      "No predicted ADR spans found for this file.\n",
      "\n",
      "=== Joined catalog (original ↔ sct) for this file ===\n",
      "Code         | Standard Text (from sct) | Label | GT Text       | GT Ranges \n",
      "-------------+--------------------------+-------+---------------+-----------\n",
      "CONCEPT_LESS | stomach rough            | ADR   | stomach rough | 17-24;5-10\n",
      "\n",
      "==========================================================================================\n",
      "### Processing: ARTHROTEC.76\n",
      "==========================================================================================\n",
      "[Info] ADR catalog size: 5\n",
      "\n",
      "=== ADR Code Assignment (Predicted ADRs) ===\n",
      "Pred ADR text         | Fuzzy code | Fuzzy std text        | Fuzzy score | Embed code | Embed std text        | Cosine\n",
      "----------------------+------------+-----------------------+-------------+------------+-----------------------+-------\n",
      "swelling              | 65124004   | swelling              | 100.0       | 65124004   | swelling              | 1.000 \n",
      "bloating              | 248490000  | bloating              | 100.0       | 248490000  | bloating              | 1.000 \n",
      "increased appetite    | 72405004   | increased appetite    | 100.0       | 72405004   | increased appetite    | 1.000 \n",
      "empty stomach feeling | 225014007  | empty stomach feeling | 100.0       | 225014007  | empty stomach feeling | 1.000 \n",
      "dry                   |            |                       | 0.0         | 16386004   | dry,itchy skin        | 0.684 \n",
      "itchy skin.           | 16386004   | dry,itchy skin        | 80.0        | 16386004   | dry,itchy skin        | 0.811 \n",
      "pain                  |            |                       | 0.0         | 65124004   | swelling              | 0.440 \n",
      "\n",
      "Agreement (fuzzy vs embedding) on assigned code: 5/7 = 71.43%\n",
      "\n",
      "=== Joined catalog (original ↔ sct) for this file ===\n",
      "Code      | Standard Text (from sct) | Label | GT Text               | GT Ranges\n",
      "----------+--------------------------+-------+-----------------------+----------\n",
      "65124004  | swelling                 | ADR   | swelling              | 0-8      \n",
      "248490000 | bloating                 | ADR   | bloating              | 10-18    \n",
      "72405004  | increased appetite       | ADR   | increased appetite    | 20-38    \n",
      "16386004  | dry,itchy skin           | ADR   | dry,itchy skin        | 62-76    \n",
      "225014007 | empty stomach feeling    | ADR   | empty stomach feeling | 40-61    \n"
     ]
    }
   ],
   "source": [
    "# Batch Task 6 runner for a few files\n",
    "\n",
    "FILES = [\"ARTHROTEC.6.\", \"ARTHROTEC.7\", \"LIPITOR.344\", \"VOLTAREN.10\", \"ARTHROTEC.76\"]\n",
    "\n",
    "# Paths (edit if yours are different)\n",
    "TEXT_DIR = \"/Users/anjalikulkarni/Desktop/Assignment1/CADEC-lPWNPfjE-/data/cadec/text\"\n",
    "ORIG_DIR = \"/Users/anjalikulkarni/Desktop/Assignment1/CADEC-lPWNPfjE-/data/cadec/original\"\n",
    "SCT_DIR  = \"/Users/anjalikulkarni/Desktop/Assignment1/CADEC-lPWNPfjE-/data/cadec/sct\"\n",
    "PRED_DIR = \"/Users/anjalikulkarni/Desktop/Assignment1/predicted\"\n",
    "\n",
    "# Options\n",
    "EMBED_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"  # or set to None to skip embeddings\n",
    "MIN_FUZZY   = 60.0\n",
    "MIN_COS     = 0.35\n",
    "\n",
    "def _clean_base(b: str) -> str:\n",
    "    # Normalize: remove trailing '.' and optional .txt/.ann\n",
    "    b = b.strip()\n",
    "    if b.endswith(\".txt\") or b.endswith(\".ann\"):\n",
    "        b = b[:-4]\n",
    "    while b.endswith(\".\"):\n",
    "        b = b[:-1]\n",
    "    return b\n",
    "\n",
    "for raw_name in FILES:\n",
    "    base = _clean_base(raw_name)\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(f\"### Processing: {base}\")\n",
    "    print(\"=\"*90)\n",
    "    try:\n",
    "        run_task6_for_file(\n",
    "            text_dir=TEXT_DIR,\n",
    "            original_dir=ORIG_DIR,\n",
    "            sct_dir=SCT_DIR,\n",
    "            predicted_dir=PRED_DIR,\n",
    "            file_basename=base,\n",
    "            embed_model_name=EMBED_MODEL,\n",
    "            topn=3,\n",
    "            min_fuzzy=MIN_FUZZY,\n",
    "            min_cos=MIN_COS,\n",
    "        )\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"[SKIP] Missing required file for {base}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {base}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c9ae3b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
